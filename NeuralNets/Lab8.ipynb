{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Let's collect some tools for this job...\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "num_classes = 10\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "# Input layers setup [one for noise and one for class label]\n",
    "noise = keras.layers.Input(shape=(latent_dim,))\n",
    "label = keras.layers.Input(shape=(1,), dtype='int32')\n",
    "label_embedding = keras.layers.Flatten()(keras.layers.Embedding(num_classes, 100)(label))\n",
    "generator_input = keras.layers.multiply([noise, label_embedding])\n",
    "# Generation of hidden layer structures\n",
    "generator_hidden = keras.layers.Dense(128 * 7 * 7, activation='relu', input_dim=latent_dim)(generator_input)\n",
    "generator_hidden = keras.layers.Reshape((7, 7, 128))(generator_hidden)\n",
    "generator_hidden = keras.layers.BatchNormalization(momentum=0.8)(generator_hidden)\n",
    "generator_hidden = keras.layers.Conv2DTranspose(128, kernel_size=2, strides=2, activation='relu')(generator_hidden)\n",
    "#generator_hidden = keras.layers.UpSampling2D()(generator_hidden)\n",
    "#generator_hidden = keras.layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(generator_hidden)\n",
    "generator_hidden = keras.layers.BatchNormalization(momentum=0.8)(generator_hidden)\n",
    "generator_hidden = keras.layers.Conv2DTranspose(64, kernel_size=2, strides=2, activation='relu')(generator_hidden)\n",
    "#generator_hidden = keras.layers.UpSampling2D()(generator_hidden)\n",
    "#generator_hidden = keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(generator_hidden)\n",
    "generator_hidden = keras.layers.BatchNormalization(momentum=0.8)(generator_hidden)\n",
    "g_image = keras.layers.Conv2DTranspose(channels, kernel_size=3, padding='same', activation='tanh')(generator_hidden)\n",
    "# Finalize the model\n",
    "generator = keras.Model([noise, label], g_image)\n",
    "generator.compile(loss=['binary_crossentropy'],optimizer=keras.optimizers.Adam(0.0002,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "# Input for discriminator model is an image...\n",
    "d_image = keras.layers.Input(shape=img_shape)\n",
    "# Hidden layers\n",
    "discriminator_hidden = keras.layers.Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding='same')(d_image)\n",
    "discriminator_hidden = keras.layers.LeakyReLU(alpha=0.2)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Dropout(0.25)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Conv2D(32, kernel_size=3, strides=2, padding='same')(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.ZeroPadding2D(padding=((0,1),(0,1)))(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.LeakyReLU(alpha=0.2)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Dropout(0.25)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.BatchNormalization(momentum=0.8)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same')(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.LeakyReLU(alpha=0.2)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Dropout(0.25)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.BatchNormalization(momentum=0.8)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same')(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.LeakyReLU(alpha=0.2)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Dropout(0.25)(discriminator_hidden)\n",
    "discriminator_hidden = keras.layers.Flatten()(discriminator_hidden)\n",
    "# Outputs will be both a probability of being \"real\" and...\n",
    "valid = keras.layers.Dense(1, activation='sigmoid')(discriminator_hidden)\n",
    "# An probability of what class (with fakes having a unique class)\n",
    "target_label = keras.layers.Dense(num_classes+1, activation='softmax')(discriminator_hidden)\n",
    "# Finalize the model\n",
    "discriminator = keras.Model(d_image, [valid, target_label])\n",
    "discriminator.compile(loss=['binary_crossentropy','sparse_categorical_crossentropy'],\n",
    "                                        optimizer=keras.optimizers.Adam(0.0002,0.5),\n",
    "                                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model...\n",
    "# When training the generator, we need to pass through the discriminator...\n",
    "# However, we don't want the discriminator to update during training\n",
    "# of the generator (which would generate a -moving target- problem\n",
    "# similar to RL agents)\n",
    "# So, we will turn the discriminator training -off- when training with\n",
    "# the combined model (combined model is really -only- used to train\n",
    "# the generator even though it shares layers with the \"trainable\"\n",
    "# discriminator that we made earlier)\n",
    "# Turn off learning for generator...\n",
    "discriminator.trainable = False\n",
    "# Make the output of the generator feed into the discriminator.\n",
    "# Note that we don't recompile the discriminator when doing this so that\n",
    "# the discriminator can still be trained independently...\n",
    "valid, target_label = discriminator(g_image) # g_image = generator output layer\n",
    "# Combined model now takes generator inputs and has discriminator outputs...\n",
    "combined = keras.Model([noise,label],[valid,target_label])\n",
    "combined.compile(loss=['binary_crossentropy','sparse_categorical_crossentropy'],\n",
    "                        optimizer=keras.optimizers.Adam(0.0002,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load image data - MNIST\n",
    "(X_train, y_train), (_, _) = keras.datasets.mnist.load_data()\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "history = [[],[],[],[]]\n",
    "batch_size = 32\n",
    "half_batch_size = int(batch_size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999 [Discriminator Loss: 1.397403, Real/Fake-Acc.: 56.25%, Classification-Acc: 56.25%] [Generator Loss: 1.550626]"
     ]
    }
   ],
   "source": [
    "# Perform some number of epochs...\n",
    "epochs = 20000\n",
    "# We need to perform this manually since the\n",
    "# training is broken into phases for each\n",
    "# component but still needs to be interleaved...\n",
    "for epoch in range(epochs):\n",
    "    # Training the discriminator...\n",
    "    # Select half of the images for the discriminator from\n",
    "    # the MNIST data set...\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch_size)\n",
    "    real_images = X_train[idx]\n",
    "    # Generate some Gaussian noise (random) 100-element vectors\n",
    "    # to provide as inputs for the generator to make some \"fakes\"\n",
    "    noise = np.random.normal(0, 1, (half_batch_size, 100))\n",
    "    # We want those random vectors to be associated with a class...\n",
    "    # That is, we are asking the generator to make these numbers...\n",
    "    sampled_labels = np.random.randint(0, 10, half_batch_size).reshape(-1, 1)\n",
    "    # Use the generator to make these images now!\n",
    "    generated_images = generator.predict([noise, sampled_labels])\n",
    "    # Generate the real-fake target distinctions\n",
    "    # Reals are 1.0 (100% real)\n",
    "    # Fakes are 0.0 (0% real)\n",
    "    valid = np.ones((half_batch_size, 1))\n",
    "    fake = np.zeros((half_batch_size, 1))\n",
    "    # Use the labeled classes for the real images...\n",
    "    image_labels = y_train[idx]\n",
    "        # Assign the fake images to the \"extra class\" or \"fake class\"\n",
    "    # on the one-hot encoding for all fake images (they are\n",
    "    # not any of the digits 0-9 since they are -fakes- so\n",
    "    # we don't used the requested generator labels...)\n",
    "    fake_labels = 10 * np.ones(half_batch_size).reshape(-1, 1)\n",
    "    # Train the discriminator - Two groups\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, [valid, image_labels])\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, [fake, fake_labels])\n",
    "    # Calculate the average for an \"overall\" loss/accuracy for the discriminator...\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    # Training the generator...\n",
    "    # Make some noise!\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    # Note that we are using the combined model to backprop the\n",
    "    # loss to the generator... we therefore need to make some targets...\n",
    "    # Call these real images! - we are trying to \"fake-out\" the\n",
    "    # discriminator, so how would we accomplish this? Set the target\n",
    "    # -as-if- the generated images were -real-!\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    # Give them some labels so the generator can learn which digit\n",
    "    # it is trying to fake.\n",
    "    sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "    # Train the generator\n",
    "    g_loss = combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])\n",
    "    # Add new results to history for plotting later...\n",
    "    history[0] += [d_loss[0]]\n",
    "    history[1] += [d_loss[3]]\n",
    "    history[2] += [d_loss[4]]\n",
    "    history[3] += [g_loss[0]]\n",
    "    # Print progress indicator\n",
    "    print(\"\\r%d [Discriminator Loss: %f, Real/Fake-Acc.: %.2f%%, Classification-Acc: %.2f%%] [Generator Loss: %f]\" % (\n",
    "                                                epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
